#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞
"""

import logging
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.dirname(__file__))

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


def test_strikeplanet_parser():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ StrikePlanet"""
    from parsers.strikeplanet_parser import StrikePlanetParser

    print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä StrikePlanet...")

    parser = StrikePlanetParser()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    html = parser.get_page(parser.catalog_url)
    if html:
        with open('debug_page.html', 'w', encoding='utf-8') as f:
            f.write(html)
        print("‚úÖ HTML —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ debug_page.html")

    # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã
    products = parser.parse_products()

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")

    for i, product in enumerate(products[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
        print(f"\n--- –¢–æ–≤–∞—Ä {i + 1} ---")
        print(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {product.get('name', '–ù–µ—Ç')}")
        print(f"–¶–µ–Ω–∞: {product.get('price', '–ù–µ—Ç')}")
        print(f"URL: {product.get('url', '–ù–µ—Ç')}")
        print(f"–í–µ—Å: {product.get('weight', '–ù–µ—Ç')}")
        print(f"–£–ø–∞–∫–æ–≤–∫–∞: {product.get('package', '–ù–µ—Ç')}")

    return products


def analyze_html_structure():
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML"""
    from bs4 import BeautifulSoup

    with open('debug_page.html', 'r', encoding='utf-8') as f:
        html = f.read()

    soup = BeautifulSoup(html, 'html.parser')

    print("\nüîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML:")

    # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–∞–º–∏
    elements_with_classes = soup.find_all(class_=True)
    class_count = {}

    for element in elements_with_classes[:100]:  # –ü–µ—Ä–≤—ã–µ 100 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for class_name in element.get('class', []):
            class_count[class_name] = class_count.get(class_name, 0) + 1

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
    common_classes = sorted(class_count.items(), key=lambda x: x[1], reverse=True)[:20]

    print("üìä –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –∫–ª–∞—Å—Å—ã:")
    for class_name, count in common_classes:
        print(f"  .{class_name}: {count} —Ä–∞–∑")

    # –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
    print("\nüîç –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤:")
    for class_name, count in common_classes:
        if any(keyword in class_name.lower() for keyword in ['product', 'item', 'card', 'goods', 'catalog']):
            elements = soup.select(f'.{class_name}')
            print(f"\nüéØ –ö–ª–∞—Å—Å .{class_name} ({count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤):")
            for i, elem in enumerate(elements[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                text = elem.get_text(strip=True)[:100]
                print(f"  {i + 1}. {text}")


if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –æ—Ç–ª–∞–¥–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞")
    print("=" * 50)

    products = test_strikeplanet_parser()

    if not products:
        print("\n‚ùå –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
        analyze_html_structure()